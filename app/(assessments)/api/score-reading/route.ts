// app/api/score-reading/route.ts
// Server-side scoring endpoint for reading comprehension questions
// Evaluates student answers and stores results in reading_scores table

import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import { createAzure } from '@ai-sdk/azure';
import { generateObject } from 'ai';
import { z } from 'zod';
import { auth } from '@clerk/nextjs/server';

export const dynamic = 'force-dynamic';
export const maxDuration = 60;

// Initialize Supabase client with anon key
const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
);

// Initialize Azure OpenAI for AI-assisted scoring
const azure = createAzure({
  resourceName: process.env.AZURE_OPENAI_RESOURCE_NAME!,
  apiKey: process.env.AZURE_OPENAI_API_KEY!,
});
const model = azure('o4-mini');

// Schema for AI evaluation of subjective questions (short_answer, essay)
const SubjectiveEvaluationSchema = z.object({
  is_correct: z.boolean(),
  points_earned: z.number().min(0),
  feedback: z.string().optional(),
  key_points_covered: z.array(z.string()).optional(),
});

// Request schema for scoring a single question
const ScoreQuestionRequestSchema = z.object({
  user_id: z.string(),
  task_id: z.string().uuid(),
  question_id: z.string().uuid(),
  user_answer: z.any(), // Can be string, number, array, or object depending on question type
  attempt_number: z.number().int().min(1).default(1),
});

// Request schema for scoring multiple questions (batch)
const BatchScoreRequestSchema = z.object({
  user_id: z.string(),
  task_id: z.string().uuid(),
  attempt_number: z.number().int().min(1).default(1),
  answers: z.array(z.object({
    question_id: z.string().uuid(),
    user_answer: z.any(),
  })),
});

/**
 * Scores a multiple choice question (objective scoring)
 */
function scoreMultipleChoice(userAnswer: any, correctAnswer: any, points: number) {
  const isCorrect = String(userAnswer).toLowerCase() === String(correctAnswer).toLowerCase();
  return {
    is_correct: isCorrect,
    points_earned: isCorrect ? points : 0,
    evaluation_data: {},
  };
}

/**
 * Scores a checkbox question (all correct answers must be selected)
 */
function scoreCheckbox(userAnswer: any, correctAnswers: string[], points: number) {
  // Normalize both arrays to strings and sort them
  const userAnswersNormalized = Array.isArray(userAnswer)
    ? userAnswer.map(a => String(a).toLowerCase()).sort()
    : [];
  const correctAnswersNormalized = correctAnswers.map(a => String(a).toLowerCase()).sort();

  const isCorrect = JSON.stringify(userAnswersNormalized) === JSON.stringify(correctAnswersNormalized);

  return {
    is_correct: isCorrect,
    points_earned: isCorrect ? points : 0,
    evaluation_data: {
      user_selections: userAnswersNormalized.length,
      required_selections: correctAnswersNormalized.length,
    },
  };
}

/**
 * Scores a true/false question
 */
function scoreTrueFalse(userAnswer: any, correctAnswer: string, points: number) {
  const isCorrect = String(userAnswer).toLowerCase() === correctAnswer.toLowerCase();
  return {
    is_correct: isCorrect,
    points_earned: isCorrect ? points : 0,
    evaluation_data: {},
  };
}

/**
 * Scores a fill in the blank question using AI
 */
async function scoreFillInBlank(userAnswer: string, correctAnswer: string, explanation: string, points: number) {
  try {
    const prompt = `Evaluate this fill-in-the-blank answer:

Correct Answer: "${correctAnswer}"
User's Answer: "${userAnswer}"
${explanation ? `Context: "${explanation}"` : ''}

Consider:
1. The meaning and intent of the answer
2. Alternative correct phrasings
3. Whether the answer demonstrates understanding of the concept

Respond with evaluation data.`;

    const { object: evaluation } = await generateObject({
      model: model,
      schema: SubjectiveEvaluationSchema,
      prompt: prompt,
    });

    return {
      is_correct: evaluation.is_correct,
      points_earned: evaluation.is_correct ? points : 0,
      evaluation_data: {
        feedback: evaluation.feedback,
        ai_evaluated: true,
      },
    };
  } catch (error) {
    console.error('‚ùå [SCORE-READING] AI evaluation failed for fill-in-blank:', error);
    // Fallback to exact match
    const isCorrect = userAnswer.toLowerCase().trim() === correctAnswer.toLowerCase().trim();
    return {
      is_correct: isCorrect,
      points_earned: isCorrect ? points : 0,
      evaluation_data: {
        fallback: 'exact_match',
        ai_error: error instanceof Error ? error.message : 'Unknown error',
      },
    };
  }
}

/**
 * Scores a short answer question using AI
 */
async function scoreShortAnswer(
  userAnswer: string,
  correctAnswer: string,
  explanation: string | undefined,
  points: number
) {
  try {
    const prompt = `Evaluate this short answer question:

Expected Answer: "${correctAnswer}"
Student's Answer: "${userAnswer}"
${explanation ? `Explanation: "${explanation}"` : ''}

Evaluate if the student's answer is correct. Consider:
1. Semantic equivalence (does it mean the same thing?)
2. Key facts and concepts covered
3. Minor wording differences are acceptable if meaning is preserved

Return is_correct as true/false and points_earned (0 to ${points}).`;

    const { object: evaluation } = await generateObject({
      model: model,
      schema: SubjectiveEvaluationSchema,
      prompt: prompt,
    });

    return {
      is_correct: evaluation.is_correct,
      points_earned: Math.min(evaluation.points_earned, points),
      evaluation_data: {
        feedback: evaluation.feedback,
        ai_evaluated: true,
      },
    };
  } catch (error) {
    console.error('‚ùå [SCORE-READING] AI evaluation failed for short answer:', error);
    return {
      is_correct: false,
      points_earned: 0,
      evaluation_data: {
        fallback: 'failed',
        ai_error: error instanceof Error ? error.message : 'Unknown error',
        requires_manual_review: true,
      },
    };
  }
}

/**
 * Scores an essay question using AI
 */
async function scoreEssay(
  userAnswer: string,
  sampleAnswer: string,
  gradingCriteria: string[] | undefined,
  minWords: number,
  maxWords: number,
  points: number
) {
  try {
    const wordCount = userAnswer.trim().split(/\s+/).length;

    if (wordCount < minWords) {
      return {
        is_correct: false,
        points_earned: 0,
        evaluation_data: {
          feedback: `Answer is too short. Minimum ${minWords} words required, got ${wordCount} words.`,
          word_count: wordCount,
          ai_evaluated: true,
        },
      };
    }

    const prompt = `Evaluate this essay answer:

Sample/Expected Answer: "${sampleAnswer}"
Student's Answer: "${userAnswer}"
${gradingCriteria ? `Grading Criteria: ${gradingCriteria.join(', ')}` : ''}

Word Count: ${wordCount} (required: ${minWords}-${maxWords})

Evaluate the essay based on:
1. Content accuracy and comprehension
2. Coverage of key points
3. Coherence and organization
4. Language use appropriate for reading comprehension

Maximum points: ${points}
Provide points_earned (0-${points}) and detailed feedback.`;

    const { object: evaluation } = await generateObject({
      model: model,
      schema: SubjectiveEvaluationSchema,
      prompt: prompt,
    });

    return {
      is_correct: evaluation.points_earned >= (points * 0.6), // 60% threshold for "correct"
      points_earned: Math.min(evaluation.points_earned, points),
      evaluation_data: {
        feedback: evaluation.feedback,
        word_count: wordCount,
        key_points_covered: evaluation.key_points_covered || [],
        ai_evaluated: true,
      },
    };
  } catch (error) {
    console.error('‚ùå [SCORE-READING] AI evaluation failed for essay:', error);
    return {
      is_correct: false,
      points_earned: 0,
      evaluation_data: {
        fallback: 'failed',
        ai_error: error instanceof Error ? error.message : 'Unknown error',
        requires_manual_review: true,
      },
    };
  }
}

/**
 * Scores a matching question
 */
function scoreMatching(userAnswer: Record<string, string>, correctAnswer: Record<string, string>, points: number) {
  const correctMatches = Object.keys(correctAnswer).filter(
    key => String(userAnswer[key]) === String(correctAnswer[key])
  ).length;

  const totalMatches = Object.keys(correctAnswer).length;
  const isCorrect = correctMatches === totalMatches;
  const pointsPerMatch = points / totalMatches;
  const pointsEarned = correctMatches * pointsPerMatch;

  return {
    is_correct: isCorrect,
    points_earned: Math.round(pointsEarned * 100) / 100,
    evaluation_data: {
      correct_matches: correctMatches,
      total_matches: totalMatches,
    },
  };
}

/**
 * Scores a sentence reordering question
 */
function scoreSentenceReordering(userAnswer: number[], correctOrder: number[], points: number) {
  const isCorrect = JSON.stringify(userAnswer) === JSON.stringify(correctOrder);
  return {
    is_correct: isCorrect,
    points_earned: isCorrect ? points : 0,
    evaluation_data: {
      user_order: userAnswer,
      correct_order: correctOrder,
    },
  };
}

/**
 * Main scoring function that delegates to specific scorers based on question type
 */
async function scoreQuestion(question: any, userAnswer: any) {
  const questionType = question.question_type;
  const questionBody = question.body;
  const maxPoints = question.points;
  const correctAnswer = question.answer;

  console.log(`üéØ [SCORE-READING] Scoring ${questionType} question #${question.question_number}`);

  switch (questionType) {
    case 'multiple_choice':
      return scoreMultipleChoice(userAnswer, correctAnswer, maxPoints);

    case 'checkbox':
      return scoreCheckbox(userAnswer, correctAnswer, maxPoints);

    case 'true_false':
      return scoreTrueFalse(userAnswer, correctAnswer, maxPoints);

    case 'fill_in_the_blanks':
      return await scoreFillInBlank(
        String(userAnswer),
        correctAnswer,
        questionBody.explanation,
        maxPoints
      );

    case 'short_answer':
      return await scoreShortAnswer(
        String(userAnswer),
        correctAnswer,
        questionBody.explanation,
        maxPoints
      );

    case 'essay':
      return await scoreEssay(
        String(userAnswer),
        questionBody.sample_answer,
        questionBody.grading_criteria,
        questionBody.min_words || 100,
        questionBody.max_words || 300,
        maxPoints
      );

    case 'match_the_following':
      return scoreMatching(userAnswer as Record<string, string>, correctAnswer, maxPoints);

    case 'sentence_reordering':
      return scoreSentenceReordering(userAnswer as number[], correctAnswer, maxPoints);

    default:
      console.warn(`‚ö†Ô∏è [SCORE-READING] Unknown question type: ${questionType}`);
      return {
        is_correct: false,
        points_earned: 0,
        evaluation_data: {
          error: 'Unknown question type',
          requires_manual_review: true,
        },
      };
  }
}

/**
 * POST endpoint to score reading questions
 * Accepts both single question scoring and batch scoring
 */
export async function POST(request: NextRequest) {
  try {
    const body = await request.json();

    // Determine if this is a batch request or single question
    const isBatch = 'answers' in body;

    if (isBatch) {
      // Batch scoring
      const validationResult = BatchScoreRequestSchema.safeParse(body);
      if (!validationResult.success) {
        return NextResponse.json(
          { error: 'Invalid request', details: validationResult.error.errors },
          { status: 400 }
        );
      }

      const { user_id, task_id, attempt_number, answers } = validationResult.data;

      console.log(`üìä [SCORE-READING] Batch scoring ${answers.length} questions for task ${task_id}`);

      // Fetch all questions for this task
      const { data: questions, error: questionsError } = await supabase
        .from('task_questions')
        .select('*')
        .eq('task_id', task_id)
        .order('question_number');

      if (questionsError || !questions) {
        return NextResponse.json(
          { error: 'Failed to fetch questions', details: questionsError },
          { status: 500 }
        );
      }

      // Score each question
      const scoredResults = [];
      for (const answer of answers) {
        const question = questions.find(q => q.id === answer.question_id);
        if (!question) {
          console.warn(`‚ö†Ô∏è [SCORE-READING] Question ${answer.question_id} not found`);
          continue;
        }

        const scoreResult = await scoreQuestion(question, answer.user_answer);

        scoredResults.push({
          question_id: answer.question_id,
          question_number: question.question_number,
          ...scoreResult,
        });

        // Save to reading_scores table
        await supabase.from('reading_scores').insert({
          user_id,
          task_id,
          question_id: answer.question_id,
          question_number: question.question_number,
          user_answer: answer.user_answer,
          correct_answer: question.answer,
          is_correct: scoreResult.is_correct,
          points_earned: scoreResult.points_earned,
          max_points: question.points,
          evaluation_data: scoreResult.evaluation_data,
          attempt_number,
        });
      }

      const totalPointsEarned = scoredResults.reduce((sum, r) => sum + r.points_earned, 0);
      const totalPointsPossible = questions.reduce((sum, q) => sum + q.points, 0);
      const percentageScore = (totalPointsEarned / totalPointsPossible) * 100;

      console.log(`‚úÖ [SCORE-READING] Batch scoring complete: ${totalPointsEarned}/${totalPointsPossible} (${percentageScore.toFixed(1)}%)`);

      return NextResponse.json({
        success: true,
        results: scoredResults,
        summary: {
          total_questions: scoredResults.length,
          total_points_earned: totalPointsEarned,
          total_points_possible: totalPointsPossible,
          percentage_score: Math.round(percentageScore * 100) / 100,
        },
      });

    } else {
      // Single question scoring
      const validationResult = ScoreQuestionRequestSchema.safeParse(body);
      if (!validationResult.success) {
        return NextResponse.json(
          { error: 'Invalid request', details: validationResult.error.errors },
          { status: 400 }
        );
      }

      const { user_id, task_id, question_id, user_answer, attempt_number } = validationResult.data;

      console.log(`üéØ [SCORE-READING] Scoring single question ${question_id} for task ${task_id}`);

      // Fetch the question
      const { data: question, error: questionError } = await supabase
        .from('task_questions')
        .select('*')
        .eq('id', question_id)
        .eq('task_id', task_id)
        .single();

      if (questionError || !question) {
        return NextResponse.json(
          { error: 'Question not found', details: questionError },
          { status: 404 }
        );
      }

      const scoreResult = await scoreQuestion(question, user_answer);

      // Save to reading_scores table
      const { error: insertError } = await supabase.from('reading_scores').insert({
        user_id,
        task_id,
        question_id,
        question_number: question.question_number,
        user_answer,
        correct_answer: question.answer,
        is_correct: scoreResult.is_correct,
        points_earned: scoreResult.points_earned,
        max_points: question.points,
        evaluation_data: scoreResult.evaluation_data,
        attempt_number,
      });

      if (insertError) {
        console.error('‚ùå [SCORE-READING] Failed to save score:', insertError);
        return NextResponse.json(
          { error: 'Failed to save score', details: insertError },
          { status: 500 }
        );
      }

      console.log(`‚úÖ [SCORE-READING] Score saved: ${scoreResult.points_earned}/${question.points}`);

      return NextResponse.json({
        success: true,
        question_id,
        question_number: question.question_number,
        ...scoreResult,
        max_points: question.points,
      });
    }

  } catch (error) {
    console.error('üí• [SCORE-READING] Error:', error);
    return NextResponse.json(
      {
        error: 'Failed to score reading question',
        details: error instanceof Error ? error.message : 'Unknown error'
      },
      { status: 500 }
    );
  }
}
